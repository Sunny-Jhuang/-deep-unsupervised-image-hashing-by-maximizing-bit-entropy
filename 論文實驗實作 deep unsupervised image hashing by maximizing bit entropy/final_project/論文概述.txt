這篇論文提出了一種稱為Contrastive Clustering (CC) 的在線聚類方法，明確執行實例和集群層次的對比學習。具體而言，對於給定的數據集，通過數據擴增構建正面和負面實例對，然後投影到特徵空間。在這裡，通過最大化正面對的相似性並最小化負面對的相似性，分別在行空間和列空間進行實例和集群層次的對比學習。其主要觀察是特徵矩陣的行可以被視為實例的軟標籤，相應地，列可以進一步被視為集群表示。通過同時優化實例和集群層次的對比損失，模型以端到端的方式學習表示和集群分配。此外，該方法能夠及時計算每個個體的集群分配，即使數據以流的形式呈現。

該論文強調了對比學習在實例和集群層次的應用，並指出特徵矩陣的行和列分別對應於實例和集群表示。作者提出的方法可以在線學習，即在數據流的情況下及時預測集群分配。通過在六個具有挑戰性的圖像基準上的廣泛實驗，該方法在性能上顯著優於17種競爭性聚類方法。特別是，在CIFAR-10（CIFAR-100）數據集上，相對於最佳基線，CC實現了0.705（0.431）的NMI，性能提升高達19%（39%）。

簡而言之，該方法的主要貢獻有：

揭示了特徵矩陣的行和列本質上對應於實例和集群表示，將深度聚類優雅地統一到表示學習框架中。
提出了特定於聚類的對比學習方法，不僅在實例級別進行對比學習，還在集群級別進行對比學習，並在實驗中證明了雙對比學習框架的優越性。
提出的模型以在線且端到端的方式工作，僅需要批次優化，因此適用於大規模數據集。此外，該方法能夠及時預測每個新來的數據點的集群分配，適用於數據流。

這部分論文介紹了相關工作，主要集中在兩個相關主題上，即對比學習和深度聚類。

對比學習（Contrastive Learning）
對比學習是近期無監督學習中的一種有前景的範式，最近在表示學習方面取得了最先進的性能。其基本思想是將原始數據映射到一個特徵空間，其中最大化正樣本的相似性，同時最小化負樣本的相似性。正樣本和負樣本的構建可以使用不同的策略，例如使用聚類結果作為偽標籤，或者直接將每個實例視為一個類別，通過數據擴增構建正負樣本對。不同的對比學習方法使用不同的損失函數，例如三元損失、NCE損失、SimCLR損失等。然而，現有方法通常僅在實例級別執行對比學習，而本文提出的方法同時在實例和集群級別執行對比學習，並針對聚類任務進行特定的對比學習。

深度聚類（Deep Clustering）
儘管傳統的聚類算法在大規模複雜數據集上取得了令人沮喪的結果，但深度聚類利用深度神經網絡的強大表示能力，在複雜數據集上取得了有希望的性能。深度聚類方法使用神經網絡提取數據的代表信息，並在迭代中更新聚類結果。與傳統的兩階段方法不同，本文提出的方法將標籤視為特殊的表示，從而在特徵矩陣的行和列空間中分別進行實例和集群級別的表示學習。相對於先前的方法，這種基於對比樣本的雙重學習範式有助於最小化不同集群之間的相似性，並且是促使聚類的對比學習的一種成功嘗試。

方法（Method）
提出的方法稱為Contrastive Clustering（CC），具體包括三個部分：對比學習、實例級別對比頭（ICH）、集群級別對比頭（CCH）。首先，通過數據擴增構建數據對，然後在特徵矩陣的行和列空間中分別應用實例和集群級別的對比學習。最後，通過梯度下降優化整體損失，該損失由實例級別和集群級別的對比損失組成。該方法在六個具有挑戰性的圖像數據集上顯著優於其他17種競爭性的聚類方法。

這篇論文的後半部分主要包含實驗結果、定性分析、消融研究以及結論。以下是對這些部分的中文翻譯和摘要：

實驗結果
作者在六個具有挑戰性的圖像數據集上評估了所提出的方法，這些數據集包括CIFAR-10、CIFAR-100、STL-10、ImageNet-10、ImageNet-Dogs和Tiny-ImageNet。使用了CIFAR-10、CIFAR-100和STL-10的訓練和測試集，而ImageNet-10、ImageNet-Dogs和Tiny-ImageNet僅使用了訓練集。作者使用了ResNet34作為骨幹網絡，保持了先前工作的公平比較。採用Adam優化器進行模型優化，採用了固定的學習率、無權重衰減和批量大小為256。評估指標包括規範化互信息（NMI）、準確度（ACC）和調整蘭德指數（ARI）。

與最新技術的比較
作者將提出的對比性聚類方法（CC）與17種代表性的最新聚類方法進行了比較，包括k均值、譜聚類、层次聚類、非負矩陣分解、自編碼器、降噪自編碼器、生成對抗網絡等。根據實驗結果，CC在所有六個數據集上明顯優於其他方法，特別是在CIFAR-10、CIFAR-100和STL-10上，相對於最接近的競爭者PICA，NMI分別提高了0.114、0.121和0.153。在ARI方面，CC在CIFAR-100和Tiny-ImageNet上實現了超過50%的性能改善。

定性研究
作者進行了定性研究，分析了模型在培訓過程中對成對相似性的變化以及對實例特徵和群集分配的演變的影響。成對相似性的變化顯示正實例/群集對的相似性隨著培訓過程的進行而增加，而負實例/群集對的相似性保持在較低水平。實例特徵和群集分配的演變研究表明，隨著培訓的進行，群集分配變得更加合理，特徵分佈更加清晰。

消融研究
為了進一步了解數據增強的重要性以及兩個對比頭的效果，作者進行了消融研究。研究結果表明，數據增強對CC的性能至關重要，特別是在較複雜的數據集（如CIFAR-10）上。此外，將實例級對比頭或群集級對比頭中的任一項刪除會影響性能，但聚類性能最好的情況是保留兩者。

結論
在這項研究中，作者提出了對比性聚類（CC）方法，該方法在實例和群集級別均進行對比性學習，並在統一框架下實現。CC在六個不同的圖像數據集上取得了優異的聚類性能，並在NMI、ACC和ARI等指標上超越了其他17種最新的聚類方法。未來，作者計劃將該方法擴展到其他任務和應用領域，例如半監督學習和遷移學習。